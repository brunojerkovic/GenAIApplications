{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:23:08.224859Z",
     "start_time": "2024-06-29T07:23:08.217860Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install duckduckgo-search\n",
    "# !pip install wikipedia\n",
    "# !pip install langchainhub\n",
    "# !pip install numexpr\n",
    "# !pip install --upgrade --quiet  langchain-community arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9482dfdad139ef",
   "metadata": {},
   "source": [
    "# 1. Basics on Using Langchain's Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e285536",
   "metadata": {},
   "source": [
    "**Note:** Chains are for stacking multiple LLM outputs (from the same or a different one), and agents are for making your AI interact with tools (using code) to get more information for creating prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4a98982c12938a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T15:17:30.908548Z",
     "start_time": "2024-06-30T15:17:30.242239Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbe67d19abc4eee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:12:32.721104Z",
     "start_time": "2024-06-29T07:12:31.926659Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ab1ce7079d415",
   "metadata": {},
   "source": [
    "### 1.1.1 Using simple prompting with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd6ec044a12abc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:13:57.450789Z",
     "start_time": "2024-06-29T07:13:56.283954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try to fin the 2023 world series champion\n",
    "message = [\n",
    "    SystemMessage(\n",
    "        content=\"A user will input in a year and you will get the baseball world series champion\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"2023\"\n",
    "    )\n",
    "]\n",
    "\n",
    "llm.invoke(message).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bbb58b7c6ff82",
   "metadata": {},
   "source": [
    "### 1.1.2 Using Langchain's agent with 'Wiki' tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8a688ed247ff50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:17:39.752550Z",
     "start_time": "2024-06-29T07:17:38.497927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example with Wikipedia tools\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wikitool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "tools = [wikitool]\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Who won 2023 world series?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a23a4d12afc03d",
   "metadata": {},
   "source": [
    "### 1.1.3 Using Langchain's agent with your own function as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d2d57eb23f438cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:56:12.652361Z",
     "start_time": "2024-06-29T08:56:10.218630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Another example with custom functions as tools\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),  # THIS IS IMPORTANT TO PROVIDE\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"what is the value of magic_function(3)?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f2c76e8a3d85",
   "metadata": {},
   "source": [
    "### 1.1.4 Using Langchain's agent with multiple tools (Wiki and duck-duck-go search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6663a2d751151489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:24:26.782882Z",
     "start_time": "2024-06-29T07:24:23.958013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example with using multiple tools\n",
    "from langchain import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Tool #1\n",
    "llm_match_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "math_tool = Tool.from_function(\n",
    "    func=llm_match_chain,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Useful for answering math questions. Only math questions and nothing else.\"\n",
    ")\n",
    "\n",
    "# Tool #2\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools2 = [search, math_tool]\n",
    "\n",
    "agent2 = create_openai_functions_agent(llm, tools2, prompt)\n",
    "\n",
    "agent_executor2 = AgentExecutor(agent=agent2, tools=tools2, verbose=True)\n",
    "agent_executor2.invoke({\"input\": \"Who won the 2021 world series and how many years was it since their last year series win?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5b6c9c50784b3",
   "metadata": {},
   "source": [
    "### 1.1.5 Using Langchain's agent with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8302f6ff2fc26d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:56:54.356037Z",
     "start_time": "2024-06-29T08:56:53.575034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using with chat history\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "    }\n",
    ")['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b86cc461a61d8",
   "metadata": {},
   "source": [
    "# 2. ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dec82373491046",
   "metadata": {},
   "source": [
    "The idea is to make the models do reasoning + acting + observing.\n",
    "It evolved from chain-of-thought (which is just about doing a few prompts together).\n",
    "\n",
    "Example:\n",
    "Question: 'Seven Brief Lesons on Physics was written by an Italian physicist that has worked in France since what year?'\n",
    "\n",
    "\n",
    "#### Standard\n",
    "Answer: 1986. **(INCORRECT)**\n",
    "\n",
    "#### Reason only\n",
    "Thought: Let's think step by step. Seven Brief Lessons on Physics was written by Carlo Rovelli. Carlo Rovelli has worked in France since 1990. \\ \n",
    "Answer: 1990. **(INCORRECT)**\n",
    "\n",
    "#### Act only\n",
    "Act 1: Search 'Seven Brief Lessons on Physics' \\\n",
    "Obs 1: Seven Brief Lessons on Physics is a short boook by the Italian physicist Carlo Rovelli. Originally published in Italian in ... \n",
    "\n",
    "Act 2: Lookup 'Carlo Rovelli' \\\n",
    "Obs 2: Seven Brief Lessons on Physics is a short book by the Italian physicst Carlo Rovelli. \n",
    "\n",
    "Act 3: Finish 1983 \\\n",
    "Answer: 1983 **(INCORRECT)**\n",
    "\n",
    "#### ReAct\n",
    "Thought 1: I need to search Seven Brief Lesons on Physics, find its author, then find when the author has worked in France since. \\\n",
    "Act 1: Search 'Seven Brief Lessons on Physics' \\\n",
    "Obs 1: Seven Brief Lessons on Physics is a short book by the Italian physicist Carlo Rovelli. Originally published ...\n",
    "\n",
    "Thought 2: The author of Seven Brief Lessons on Physics is Carlo Rovelli. I need to search Carlo Rovelli next and find when he has worked in France since. \\\n",
    "Act 2: Search 'Carlo Rovelli' \\\n",
    "Obs 2: Carlo Rovelli is an Italian theoretical physicst and writer who has worked in Italy, the United States, and since 2000, in France. He is also currently a Distinguished Chair at the ... \n",
    "\n",
    "Thought 3: Carlo Rovelli has worked in France since 2000. So the answer is 2000. \\\n",
    "Act 3: Finish 2000\n",
    "\n",
    "Answer: 2000  **(CORRECT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71e6fd37e4b1610a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T07:58:25.646299Z",
     "start_time": "2024-06-29T07:58:24.781085Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d38a03af7a6d8",
   "metadata": {},
   "source": [
    "## 2.1 Using a Simple Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e8a9b0195654502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:01:35.092199Z",
     "start_time": "2024-06-29T08:01:32.259768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple prompt\n",
    "\n",
    "prompt = \"How would I get from Singapore to San Francisco?\"\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7ff218dfdb805",
   "metadata": {},
   "source": [
    "## 2.2 Using Chain-of-thought prompt framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c422136752ed38c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:01:43.691185Z",
     "start_time": "2024-06-29T08:01:39.929015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chain of thought\n",
    "\n",
    "prompt = \"Explain step by step. How would I get from Singapore to San Francisco?\"\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcf8164b87c808",
   "metadata": {},
   "source": [
    "## 2.3 Using ReAct prompt framework (manually; not with langchain's agent yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4120e04de30c2d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:03:56.372034Z",
     "start_time": "2024-06-29T08:03:54.120154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manual ReAct (few-shot prompting on how to do ReAct to answer; THIS IS WITHOUT ACTUALLY USING TOOLS)\n",
    "\n",
    "question = \"How old is the president of the United States?\"\n",
    "manual_react = f\"\"\"Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
    "Thought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
    "Action: Search[Colorado orogeny]\n",
    "Observation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
    "Thought: It does not mention the eastern sector. So I need to look up eastern sector.\n",
    "Action: Lookup[eastern sector]\n",
    "Observation: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
    "Thought: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
    "Action: Search[High Plains]\n",
    "Observation: High Plains refers to one of two distinct land regions\n",
    "Thought: I need to instead search High Plains (United States).\n",
    "Action: Search[High Plains (United States)]\n",
    "Observation: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\n",
    "Thought: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
    "Action: Finish[1,800 to 7,000 ft]\n",
    "\n",
    "Question: Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
    "Thought: The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
    "Action: Search[Milhouse]\n",
    "Observation: Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
    "Thought: The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
    "Action: Lookup[named after]\n",
    "Observation: (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
    "Thought: Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
    "Action: Finish[Richard Nixon]\n",
    "\n",
    "Question: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
    "Thought: I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.\n",
    "Action: Search[Adam Clayton Powell]\n",
    "Observation: Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell III’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office Building’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell (film)’, ’Giancarlo Esposito’].\n",
    "Thought: To find the documentary, I can search Adam Clayton Powell (film).\n",
    "Action: Search[Adam Clayton Powell (film)]\n",
    "Observation: Adam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the rise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the PBS series The American Experience.\n",
    "Thought: Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.\n",
    "Action: Finish[The Saimaa Gesture]\n",
    "\n",
    "Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
    "Thought: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
    "Action: Search[Nicholas Ray]\n",
    "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
    "Thought: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
    "Action: Search[Elia Kazan]\n",
    "Observation: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
    "Thought: Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
    "Action: Finish[director, screenwriter, actor]\n",
    "\n",
    "Question: Which magazine was started first Arthur’s Magazine or First for Women?\n",
    "Thought: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
    "Action: Search[Arthur’s Magazine]\n",
    "Observation: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
    "Thought: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
    "Action: Search[First for Women]\n",
    "Observation: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
    "Thought: First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.\n",
    "Action: Finish[Arthur’s Magazine]\n",
    "\n",
    "Question:{question}\"\"\"\n",
    "\n",
    "llm.invoke(manual_react).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69ce48d254739f",
   "metadata": {},
   "source": [
    "#### How are agents different from ReAct?\n",
    "ReAct is just a framework of reasoning-action-observation. The idea is to feed a model multiple examples of this structure (few-shot prompting). You use different tools for actions and their outputs determine what is the observation. Keep in mind that there is also **ZERO-SHOT REACT**. There you simply explain to the model what components of ReAct are, without providing actual examples. \\\n",
    "On the other hand, using agents (in langchain) just refers to using actions. You can use actions for an action-only framework (as seen above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348314f65443b4e",
   "metadata": {},
   "source": [
    "# 3. Using langchain's Agents with React framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d35374d1dca03b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:12:52.383746Z",
     "start_time": "2024-06-29T09:12:51.749747Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING TOOL: arxiv\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv = ArxivAPIWrapper()\n",
    "docs = arxiv.run(\"1605.08386\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c625e1808c35fbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T08:49:41.516486Z",
     "start_time": "2024-06-29T08:49:36.789683Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING AGENT (WITH 'arxiv' TOOL)\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "tools = load_tools(\n",
    "    [\"arxiv\"],\n",
    ")\n",
    "prompt = hub.pull(\"hwchase17/react\")  # THIS MAKES THE AGENT USE REACT PROMPT FRAMEWORK\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What's the paper 1605.08386 about?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99a1f056e2388b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:14:26.264646Z",
     "start_time": "2024-06-29T09:14:25.509430Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING TOOL: Wikipedia\n",
    "\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wikitool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "wikitool.run(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53376739e678a7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:15:23.784708Z",
     "start_time": "2024-06-29T09:15:20.523238Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING AGENT (WITH 'Wikipedia' TOOL)\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import create_react_agent\n",
    "\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wikitool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "tools = [wikitool]\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Who won 2023 world series?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86d9e3a703a97ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T10:13:36.950880Z",
     "start_time": "2024-06-29T10:13:32.611157Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING AGENT (WITH your function AS A TOOL)\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, create_react_agent, tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "@tool\n",
    "def magic_function(input: str) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return str(int(input) + 2)\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "agent = create_react_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"what is the value of magic_function(3)?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e4f70e8fa08b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T15:26:13.660328Z",
     "start_time": "2024-06-30T15:26:12.875555Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d618e097cb72e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:32.277216Z",
     "start_time": "2024-06-30T16:09:30.170071Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f5639ff534dfb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:32.792652Z",
     "start_time": "2024-06-30T16:09:32.277216Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b63b7a3e6fb7c8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:33.909394Z",
     "start_time": "2024-06-30T16:09:32.792652Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71c4d8de0a9abc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:34.796836Z",
     "start_time": "2024-06-30T16:09:33.909394Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46818f92f16f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
