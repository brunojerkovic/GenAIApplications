{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-12T09:15:29.439741Z",
     "start_time": "2024-07-12T09:15:27.042470Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompt Template\n",
    "Smarter f-strings."
   ],
   "id": "e1e607fe91cff914"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:15:48.396308Z",
     "start_time": "2024-07-12T09:15:46.560226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple input-output LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "our_prompt = \"\"\"\n",
    "I love trips, and I have been to 6 countries.\n",
    "I plan to visit a few more soon.\n",
    "\n",
    "Can you create a post for tweet in 10 words for the above?\n",
    "\"\"\"\n",
    "\n",
    "print(llm.invoke(our_prompt).content)"
   ],
   "id": "3fe0736c736e476d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Travel bug bit me hard, visited 6 countries, more coming soon! #wanderlust\"\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:15:50.093446Z",
     "start_time": "2024-07-12T09:15:48.396308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using F-strings (a simplistic way of what prompt-template tries to do)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "our_text = \"I love trips, and I have been to 6 countries. I plan to visit a few more soon.\"\n",
    "words_count = 10\n",
    "\n",
    "our_prompt = f\"\"\"\n",
    "{our_text}\n",
    "\n",
    "Can you create a post for a tweet in {words_count} words for the above?\n",
    "\"\"\"\n",
    "\n",
    "print(llm.invoke(our_prompt).content)"
   ],
   "id": "19d9dc09e787118",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Travel enthusiast: 6 countries down, more adventures on the horizon! ‚úàÔ∏èüåç\"\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:15:51.684923Z",
     "start_time": "2024-07-12T09:15:50.093446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A prompt template example - smart, reusable f-string templates\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "template = \"\"\"\n",
    "{our_text}\n",
    "\n",
    "Can you create a post for a tweet in {words_count} words for the above?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"our_text\", \"words_count\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(words_count=3, our_text=\"I love trips, and I have been to 6 countries. I plan to visit a few more soon.\")\n",
    "print(llm.invoke(final_prompt).content)"
   ],
   "id": "ecee459b98ecf964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Traveling is life! ‚úàÔ∏èüåç #wanderlust\"\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving and Loading Prompts",
   "id": "cecd74737b76ea7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:17:30.009691Z",
     "start_time": "2024-07-12T09:17:29.994053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Prompt: \", prompt)\n",
    "prompt.save(\"my_prompt.json\")"
   ],
   "id": "c5bc58f7b3c340b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  input_variables=['our_text', 'words_count'] template='\\n{our_text}\\n\\nCan you create a post for a tweet in {words_count} words for the above?\\n'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:17:43.704643Z",
     "start_time": "2024-07-12T09:17:43.673393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt_loaded = load_prompt(\"my_prompt.json\")\n",
    "print(\"Prompt: \", prompt_loaded)"
   ],
   "id": "c4856beaa4f29162",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  input_variables=['our_text', 'words_count'] template='\\n{our_text}\\n\\nCan you create a post for a tweet in {words_count} words for the above?\\n'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example Selectors\n",
    "For multiple examples (like few-shot prompting)."
   ],
   "id": "e09443c116e42e72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:51:00.265097Z",
     "start_time": "2024-06-17T06:50:58.329558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple prompt example\n",
    "our_prompt = \"\"\"\n",
    "You are a 5 year old girl, who is very funny, mischievous and sweet:\n",
    "\n",
    "Question: What is a house?\n",
    "Response: ''\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=.9)\n",
    "print(llm.invoke(our_prompt).content)"
   ],
   "id": "4062708511018984",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A house is like a giant cozy hug with a roof on top! It's where you can play hide and seek, have sleepovers with your friends, and eat lots of yummy snacks. It's like your own magical castle where you can make the rules and have adventures every day!\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:51:24.737612Z",
     "start_time": "2024-06-17T06:51:22.983771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FewShotPrompting - a way of giving your model some examples in the prompt before asking it for an answer\n",
    "our_prompt = \"\"\"\n",
    "You are a 5 year old girl, who is very funny, mischievous and sweet:\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: What is a mobile?\n",
    "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games and videos.\n",
    "\n",
    "Questions: What are your dreams?\n",
    "Response: My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles and ice-cream.\n",
    "\n",
    "Question: What is a house?\n",
    "Response: ''\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=.9)\n",
    "print(llm.invoke(our_prompt).content)"
   ],
   "id": "be59d932118ec323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A house is a big cozy hug that keeps you safe from monsters under the bed. It's where you can have pillow forts and dance parties!\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:53:55.064898Z",
     "start_time": "2024-06-17T06:53:53.104250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FewShotPrompts - a structured way of providing examples in your prompts\n",
    "# A dict structure for the examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What is a mobile?\",\n",
    "        \"answer\": \"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games and videos.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are your dreams?\",\n",
    "        \"answer\": \"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles and ice-cream.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Template used to give the examples to the model\n",
    "example_template = \"\"\"\n",
    "Question: {query}\n",
    "Response: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# Instructions that come before the examples (here can be role specification, or similar)\n",
    "prefix = \"\"\"\n",
    "You are a five year old girl, who is very funny, mischievous and sweet:\n",
    "Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions that come after the examples (here should be the actual question)\n",
    "suffix = \"\"\"\n",
    "Question: {user_input}\n",
    "Response: ''\n",
    "\"\"\"\n",
    "\n",
    "# Specifying a prompt template (smart f-string) for the examples\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Connecting everything for a reusable template of providing examples to prompts\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"user_input\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Try it out\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "query = few_shot_prompt_template.format(user_input=\"What is a house?\")\n",
    "print(llm.invoke(query).content)"
   ],
   "id": "7c403455f684ce75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A house is a big cozy nest where my toys and I live happily ever after. It's where I have tea parties and build forts with blankets and pillows.\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Length Based (Example Selector)\n",
    "Constraint on the number of examples based on the max number of tokens."
   ],
   "id": "1099390a4011a80e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:55:22.839837Z",
     "start_time": "2024-06-17T06:55:21.292203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A dict structure for the examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What is a mobile?\",\n",
    "        \"answer\": \"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games and videos.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are your dreams?\",\n",
    "        \"answer\": \"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles and ice-cream.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Template used to give the examples to the model\n",
    "example_template = \"\"\"\n",
    "Question: {query}\n",
    "Response: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# Instructions that come before the examples (here can be role specification, or similar)\n",
    "prefix = \"\"\"\n",
    "You are a five year old girl, who is very funny, mischievous and sweet:\n",
    "Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions that come after the examples (here should be the actual question)\n",
    "suffix = \"\"\"\n",
    "Question: {user_input}\n",
    "Response: ''\n",
    "\"\"\"\n",
    "\n",
    "# Specifying a prompt template (smart f-string) for the examples\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Constraining the number of examples in the prompt based on MAX_TOKEN count - useful for smaller LLM costs\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50\n",
    ")\n",
    "\n",
    "# Connecting everything for a reusable template of providing examples to prompts\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"user_input\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Try it out\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "query = few_shot_prompt_template.format(user_input=\"What is a house?\")\n",
    "print(query)\n",
    "print(llm.invoke(query).content)"
   ],
   "id": "956dbb6215905583",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a five year old girl, who is very funny, mischievous and sweet:\n",
      "Here are some examples:\n",
      "\n",
      "\n",
      "\n",
      "Question: What is a mobile?\n",
      "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games and videos.\n",
      "\n",
      "\n",
      "\n",
      "Question: What is a house?\n",
      "Response: ''\n",
      "\n",
      "A house is like a giant puzzle that you get to live in! It's where you keep all your toys and have sleepovers with your friends.\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:55:37.919657Z",
     "start_time": "2024-06-17T06:55:36.256374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding more examples for the ExamplePrompt\n",
    "new_example = {\n",
    "    \"query\": \"What is your favourite work?\",\n",
    "    \"answer\": \"sleep\"\n",
    "}\n",
    "few_shot_prompt_template.example_selector.add_example(new_example)\n",
    "\n",
    "# Try it out\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "query = few_shot_prompt_template.format(user_input=\"What is a house?\")\n",
    "print(query)\n",
    "print(llm.invoke(query).content)"
   ],
   "id": "3a2d9741aa6f54a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a five year old girl, who is very funny, mischievous and sweet:\n",
      "Here are some examples:\n",
      "\n",
      "\n",
      "\n",
      "Question: What is a mobile?\n",
      "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games and videos.\n",
      "\n",
      "\n",
      "\n",
      "Question: What is a house?\n",
      "Response: ''\n",
      "\n",
      "A house is like a big cozy blanket that protects you from the outside world. It's where all the best snacks are kept and where you can have pillow fights with your family!\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Output Parser\n",
    "For telling an LLM which output you want. Sometimes you might need only a smarter model in order to handle this."
   ],
   "id": "a3531842d922a1d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:45:50.147303Z",
     "start_time": "2024-06-17T06:45:47.102611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CSV\n",
    "\n",
    "# Telling the model how you want it to format the result\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "# The prompt template (smart f-string)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Provide 5 examples of {query}.\\n{format_instructions}\",\n",
    "    input_variable=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Try it out (does not work as good with gpt-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "query = prompt.format(query=\"Currencies\")\n",
    "print(llm.invoke(query).content)\n",
    "\n",
    "# Try it out (smarter model works better)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "query = prompt.format(query=\"Currencies\")\n",
    "print(llm.invoke(query).content)"
   ],
   "id": "68808d64300a7e2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "1. US Dollar\n",
      "2. Euro\n",
      "3. Japanese Yen\n",
      "4. British Pound\n",
      "5. Australian Dollar\n",
      "U.S. Dollar,Euro,Japanese Yen,British Pound,Australian Dollar\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:58:30.448372Z",
     "start_time": "2024-06-17T06:58:28.719778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# JSON\n",
    "\n",
    "# To specify specific text that will be added to LLM's output (for JSON outputs) - this is not added by the model, but it is post-processed\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"currency\", description=\"answer to the user's question\"),\n",
    "    ResponseSchema(name=\"abbreviation\", description=\"Whats the abbreviation of that currency\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "print(output_parser)\n",
    "\n",
    "# Specifying the output parser (the format to add to the JSON output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "# An example of a prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user's question as best as possible.\\n{format_instructions}\\n{query}\",\n",
    "    input_variable=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Try it out\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "query = prompt.format(query=\"What's the currency of India?\")\n",
    "print(llm.invoke(query).content)"
   ],
   "id": "40dddd622e97e1c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_schemas=[ResponseSchema(name='currency', description=\"answer to the user's question\", type='string'), ResponseSchema(name='abbreviation', description='Whats the abbreviation of that currency', type='string')]\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"currency\": string  // answer to the user's question\n",
      "\t\"abbreviation\": string  // Whats the abbreviation of that currency\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"currency\": \"Indian Rupee\",\n",
      "\t\"abbreviation\": \"INR\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
